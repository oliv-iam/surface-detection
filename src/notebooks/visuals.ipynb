{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e97bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5449e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/c/Users/olivi/OneDrive - Amherst College/6 Summer 2025/surface-detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6380b4",
   "metadata": {},
   "source": [
    "##### 128x2 Variable Threshold Sequence Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [\n",
    "    [25, 26, 27, 28, 28],\n",
    "    [21, 17, 21, 20, 21],\n",
    "    [19, 14, 22, 25, 25],\n",
    "    [25, 22, 27, 24, 27],\n",
    "    [24, 22, 24, 26, 25]\n",
    "]\n",
    "\n",
    "s1_counts = [\n",
    "    [156, 145, 154, 160, 142], # User 1\n",
    "    [149, 130, 156, 136, 120], # User 2\n",
    "    [142, 103, 142, 152, 137], # User 3\n",
    "    [145, 144, 159, 149, 142], # User 4\n",
    "    [137, 138, 136, 124, 134]  # User 5\n",
    "]\n",
    "\n",
    "locations = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "labels = [\"User 1\", \"User 2\", \"User 3\", \"User 4\", \"User 5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_counts = [\n",
    "    [156, 147, 154, 160, 143], # User 1\n",
    "    [158, 125, 155, 137, 122],\n",
    "    [147, 100, 145, 153, 140],\n",
    "    [150, 153, 161, 150, 148],\n",
    "    [149, 143, 147, 157, 140]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae02916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_barplot(split, title=\"\"):\n",
    "    colors = plt.get_cmap('Set2').colors\n",
    "\n",
    "    split = np.array(split)\n",
    "    x = np.arange(5)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    bottom = np.zeros(5)\n",
    "    for i, row in enumerate(split):\n",
    "        ax.bar(x, row, bottom=bottom, label=labels[i], color = colors[i])\n",
    "        bottom += row \n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(locations)\n",
    "    ax.set_xlabel(\"Location\")\n",
    "    ax.set_ylabel(\"Number of Sequences\")\n",
    "\n",
    "    # ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.12), ncol=5)\n",
    "    pos = ax.get_position()\n",
    "    ax.set_position([pos.x0, pos.y0, pos.width * 0.9, pos.height])\n",
    "    ax.legend(loc='center right', bbox_to_anchor=(1.25, 0.5))\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts: stacked barplot\n",
    "dataset_barplot(s2_counts)\n",
    "\n",
    "# thresholds: line plot\n",
    "colors = plt.get_cmap('Set3').colors\n",
    "for i in range(5):\n",
    "    plt.plot(locations, thresholds[i], label=labels[i], color = colors[i])\n",
    "plt.legend()\n",
    "plt.xlabel(\"Location\")\n",
    "plt.ylabel(\"Peak Acceleration Threshold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02fe8b2",
   "metadata": {},
   "source": [
    "##### Single sequence (normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea08225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_norm(user=1, location=\"A\", instance=1):\n",
    "    A1 = pd.read_csv(f\"{path}/sequences/varied-threshold/User{user}_Location{location}_Normal_{instance}.dat\", header=None)\n",
    "    plt.plot(list(range(1, 129)), A1[0] / A1[0].max(), label='acceleration')\n",
    "    plt.plot(list(range(1, 129)), A1[1] / A1[1].max(), color='red', label=\"Gyroscope\")\n",
    "    plt.title(\"Normalized Accelerometer, Gyroscope for Sequence\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "sequence_norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c2f78",
   "metadata": {},
   "source": [
    "##### Dataset split visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset partitions, filenames\n",
    "lines = []\n",
    "with open(f\"{path}/sequences/filenames.txt\", 'r') as filenames:\n",
    "    lines = filenames.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6079278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_barplot(filepath, title):\n",
    "    indices = []\n",
    "    with open(filepath) as f:\n",
    "        indices = f.readlines()\n",
    "    counts = [[0 for i in range(0, 5)] for j in range(0, 5)] # initialize to zeros\n",
    "    for i in indices:\n",
    "        user = 0\n",
    "        match lines[int(i.strip())-1].split('_')[0]:\n",
    "            case \"User1\" : user = 0\n",
    "            case \"User2\" : user = 1\n",
    "            case \"User3\" : user = 2\n",
    "            case \"User4\" : user = 3\n",
    "            case \"User5\" : user = 4\n",
    "        match lines[int(i.strip())-1].split('_')[1]:\n",
    "            case \"LocationA\" : counts[user][0] += 1\n",
    "            case \"LocationB\" : counts[user][1] += 1\n",
    "            case \"LocationC\" : counts[user][2] += 1\n",
    "            case \"LocationD\" : counts[user][3] += 1\n",
    "            case \"LocationE\" : counts[user][4] += 1\n",
    "    dataset_barplot(counts, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d17191",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_barplot(f\"{path}/logs/dataset-info/u5out_train.txt\", \"Training Set\")\n",
    "split_barplot(f\"{path}/logs/dataset-info/u5out_val.txt\", \"Validation Set\")\n",
    "split_barplot(f\"{path}/logs/dataset-info/u5out_test.txt\", \"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12dd00",
   "metadata": {},
   "source": [
    "##### Confusion heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d989d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix heatmap, normalized over true (rows)\n",
    "def confusion_heatmap(model=\"ver6\", fsetname=\"train\", setname=\"Training\", dataset=1):\n",
    "    set= pd.read_csv(f\"{path}/logs/set-results/{model}_accuracy_{fsetname}_set{dataset}.txt\")\n",
    "    sklearn.metrics.ConfusionMatrixDisplay.from_predictions(set[\"True\"], set[\"Predicted\"], \n",
    "                                                            cmap='cividis', \n",
    "                                                            display_labels=[\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
    "                                                            normalize=\"true\")\n",
    "    plt.xlabel(\"Predicted location\")\n",
    "    plt.ylabel(\"True location\")\n",
    "    plt.title(f\"{model.capitalize()} Predictions on {setname.capitalize()} Set (Set {dataset})\")\n",
    "    plt.savefig(f\"{path}/figures/set-results/{model}_confusion_{fsetname}_set{dataset}.png\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e41cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"ver7\" \n",
    "set = 2\n",
    "confusion_heatmap(model, \"train\", \"training\", set)\n",
    "confusion_heatmap(model, \"val\", \"validation\", set)\n",
    "confusion_heatmap(model, \"test\", \"test\", set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ed3590",
   "metadata": {},
   "source": [
    "##### Accuracy, Precision and Recall Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = [\"ver2\", \"ver3\", \"ver4\", \"ver5a\", \"ver5b\", \"ver6\", \"ver7\"]\n",
    "sets = [\"train\", \"val\", \"test\"]\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\"]\n",
    "trials = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(metric=\"accuracy\", trial=1):\n",
    "    x = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
    "    for k in range(len(versions)):\n",
    "        model = versions[k]\n",
    "        y = []\n",
    "        if model == \"ver2\" and trial == 1:\n",
    "            continue\n",
    "        for i in range(len(sets)):\n",
    "            guesses = pd.read_csv(f\"{path}/logs/nn-results/{model}_accuracy_{sets[i]}_{trial}.txt\")\n",
    "            confusion = sklearn.metrics.confusion_matrix(guesses[\"True\"], guesses[\"Predicted\"])\n",
    "            if metric == \"precision\":\n",
    "                # precision = TP / (TP + FP)\n",
    "                y.append([confusion[j][j] / np.sum(confusion[:, j]) for j in range(len(x))])\n",
    "            elif metric == \"recall\":\n",
    "                # recall = TP / (TP + FN)\n",
    "                y.append([confusion[j][j] / np.sum(confusion[j]) for j in range(len(x))])\n",
    "            else:\n",
    "                # accuracy = true predictions / all predictions\n",
    "                y.append([np.trace(confusion) / np.sum(confusion) for j in range(len(x))])\n",
    "\n",
    "        colors = plt.get_cmap('Set2').colors\n",
    "\n",
    "        ax1.plot(x, y[0], label=model, color=colors[k])\n",
    "        ax2.plot(x, y[1], label=model, color=colors[k])\n",
    "        ax3.plot(x, y[2], label=model, color=colors[k])\n",
    "\n",
    "        if trial == 1:\n",
    "            trialname = \"Even\"\n",
    "        else:\n",
    "            trialname = \"U5 Separate\"\n",
    "    \n",
    "    ax1.set_ylabel(metric.capitalize())\n",
    "    ax2.set_xlabel(\"Location\")\n",
    "    ax2.set_title(f\"{metric.capitalize()} on Training, Validation, and Test Sets ({trialname})\")\n",
    "    ax3.legend(loc='center right', bbox_to_anchor=(1.34, 0.5))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{path}/figures/nn-results/{metric}_{trial}.png\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison(\"accuracy\", 1)\n",
    "comparison(\"accuracy\", 2)\n",
    "comparison(\"recall\", 1)\n",
    "comparison(\"recall\", 2)\n",
    "comparison(\"precision\", 1)\n",
    "comparison(\"precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d56e0",
   "metadata": {},
   "source": [
    "##### Recall vs. Class Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3891e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_counts = [729, 660, 747, 721, 675]\n",
    "versions = [\"ver2\", \"ver3\", \"ver4\", \"ver5a\", \"ver5b\", \"ver6\", \"ver7\"]\n",
    "sets = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# count true positives across versions\n",
    "tps = [[0, 0, 0, 0, 0] for i in range(len(sets))]\n",
    "for i in range(len(versions)):\n",
    "    model = versions[i]\n",
    "    for j in range(len(sets)):\n",
    "        guesses = pd.read_csv(f\"{path}/logs/nn-results/{model}_accuracy_{sets[j]}_2.txt\")\n",
    "        confusion = sklearn.metrics.confusion_matrix(guesses[\"True\"], guesses[\"Predicted\"], normalize=\"true\")\n",
    "        for k in range(5):\n",
    "            tps[j][k] += confusion[k][k]\n",
    "\n",
    "# calculate average and recall (TP / (TP + FN))\n",
    "for i in range(len(sets)):\n",
    "    for j in range(5):\n",
    "        tps[i][j] = (tps[i][j] / len(versions))\n",
    "\n",
    "# plot\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax1.scatter(s1_counts, tps[0])\n",
    "ax2.scatter(s1_counts, tps[1])\n",
    "ax3.scatter(s1_counts, tps[2])\n",
    "\n",
    "# labels\n",
    "ax1.set_title(\"Training Set\")\n",
    "ax2.set_title(\"Validation Set\")\n",
    "ax3.set_title(\"Test Set\")\n",
    "ax1.set_ylabel(\"Recall\")\n",
    "ax2.set_xlabel(\"Items in Class\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surf_24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
